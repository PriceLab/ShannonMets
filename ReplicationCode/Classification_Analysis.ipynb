{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run order - 2\n",
    "# Needed input files: 'chemistries_git.csv', 'second_genome_2.csv', 'data_discovery.csv', 'top_11_mets.csv'\n",
    "# Generated output files: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 78)\n",
      "(540, 660)\n",
      "(399, 665)\n"
     ]
    }
   ],
   "source": [
    "#Importing discovery cohort Clinical labs data\n",
    "chemistries_discovery=pd.read_csv('chemistries_git.csv', \n",
    "                          index_col = 'public_client_id')\n",
    "chemistries_discovery.index=chemistries_discovery.index.astype('float64')\n",
    "#check correct sample size\n",
    "print (chemistries_discovery.shape)\n",
    "#Importing Validation cohort metabolomics data\n",
    "second_genome=pd.read_csv('second_genome_2.csv', \n",
    "                          index_col = 'public_client_id')\n",
    "second_genome.index=second_genome.index.astype('float64')\n",
    "#check correct sample size\n",
    "print (second_genome.shape)\n",
    "#Importing discovery metabolomics data\n",
    "discovery_mets=pd.read_csv('data_discovery.csv', \n",
    "                          index_col = 'public_client_id')\n",
    "discovery_mets.index=discovery_mets.index.astype('float64')\n",
    "#check correct sample size\n",
    "print (discovery_mets.shape)\n",
    "#import list of top 11 metabolites from LASSSO\n",
    "top_11_=pd.read_csv('top_11_mets.csv', \n",
    "                          index_col = 0)\n",
    "top_11_=top_11_.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 659)\n"
     ]
    }
   ],
   "source": [
    "#Scale and standardize metabolites discovery\n",
    "X = discovery_mets[discovery_mets.columns[0:659]]\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "Xcolumns=X.columns\n",
    "X = scaler.fit_transform(X)\n",
    "X=pd.DataFrame(data=X,columns=Xcolumns)\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 659)\n"
     ]
    }
   ],
   "source": [
    "#Scale and standardize metabolites validation\n",
    "vendor = second_genome[second_genome.columns[0:659]]\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "Xcolumns=vendor.columns\n",
    "vendor = scaler.fit_transform(vendor)\n",
    "vendor=pd.DataFrame(data=vendor,columns=Xcolumns)\n",
    "print (vendor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 11)\n",
      "(540, 11)\n",
      "100\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "#Prepare data for RF classifier\n",
    "classifier=pd.DataFrame(index=discovery_mets.index,data=X.set_index(discovery_mets.index))\n",
    "classifier_validation=pd.DataFrame(index=second_genome.index,data=vendor.set_index(second_genome.index))\n",
    "#Retain only the 11 metabolites in df\n",
    "for x in classifier.columns.tolist():\n",
    "    if x not in top_11_:\n",
    "        classifier.drop([x],1,inplace=True)\n",
    "print(classifier.shape)\n",
    "for x in classifier_validation.columns.tolist():\n",
    "    if x not in top_11_:\n",
    "        classifier_validation.drop([x],1,inplace=True)\n",
    "print (classifier_validation.shape)\n",
    "#Generate quartiles\n",
    "classifier['shannon_quant']=pd.qcut(discovery_mets['shannon'],4,labels=False)\n",
    "classifier_validation['shannon_quant']=pd.qcut(second_genome['shannon'],4,labels=False)\n",
    "#recode quartiles\n",
    "a=[]\n",
    "for x in classifier['shannon_quant']:\n",
    "    if x==0:\n",
    "        a.append(1)\n",
    "    else:\n",
    "        a.append(0)\n",
    "classifier['shannon_quant']=a\n",
    "print (classifier['shannon_quant'].sum())\n",
    "classifier.drop(['shannon_quant'],1,inplace=True)\n",
    "b=[]\n",
    "for x in classifier_validation['shannon_quant']:\n",
    "    if x==0:\n",
    "        b.append(1)\n",
    "    else:\n",
    "        b.append(0)\n",
    "classifier_validation['shannon_quant']=b\n",
    "print (classifier_validation['shannon_quant'].sum())\n",
    "classifier_validation.drop(['shannon_quant'],1,inplace=True)\n",
    "shannon_clf = RandomForestClassifier(n_estimators=2000,\n",
    "                                 criterion='entropy',\n",
    "                                 bootstrap=True, oob_score=False,class_weight={0:1,1:3.5},\n",
    "                                 max_features='sqrt',\n",
    "                                 min_samples_split=2,\n",
    "                                 min_samples_leaf=2,\n",
    "                                 max_depth=5,\n",
    "                                 random_state=1,\n",
    "                                 n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Random forest 10-fold CV on the discovery cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 PR AUC=0.8054\n",
      "Fold 2 PR AUC=0.5833\n",
      "Fold 3 PR AUC=0.8264\n",
      "Fold 4 PR AUC=0.6564\n",
      "Fold 5 PR AUC=0.8055\n",
      "Fold 6 PR AUC=0.6580\n",
      "Fold 7 PR AUC=0.8190\n",
      "Fold 8 PR AUC=0.8111\n",
      "Fold 9 PR AUC=0.8450\n",
      "Fold 10 PR AUC=0.7892\n",
      "mean sensitivity discovery 0.72\n",
      "mean specificity discovery 0.9031034482758621\n",
      "mean precision discovery 0.7206313131313131\n",
      "mean PR AUC 0.7599295308547271\n",
      "std dev. 0.08665212426781399\n",
      "mean ROC AUC 0.8840689655172413\n",
      "std_dev ROC AUC 0.044473556326354025\n"
     ]
    }
   ],
   "source": [
    "X = classifier.reset_index()\n",
    "X.drop(['public_client_id'],1,inplace=True)\n",
    "X=np.array(X)\n",
    "y=np.array(a)\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "\n",
    "# Perform 10-fold RF CV, extract sensitivity, specificity, precision and AUCs for each test set\n",
    "FOLDS=10\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "reversed_mean_precision = 0.0\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "mean_precision=[]\n",
    "pr_auc=[]\n",
    "tprs = []\n",
    "aucs = []\n",
    "total_specificity=[]\n",
    "total_sensitivity=[]\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "i = 0\n",
    "for train, test in cv.split(X, y):\n",
    "    probas_ = shannon_clf.fit(X[train], y[train]).predict_proba(X[test])\n",
    "    preds=shannon_clf.predict(X[test])\n",
    "    tn, fp, fn, tp = confusion_matrix(y[test],preds).ravel()\n",
    "    sensitivity=(tp/(tp+fn))\n",
    "    specificity=(tn/(tn+fp))\n",
    "    mean_precision.append(precision_score(y[test],preds))\n",
    "    total_specificity.append(specificity)\n",
    "    total_sensitivity.append(sensitivity)\n",
    "    precision, recall, thresholds= precision_recall_curve(y[test], probas_[:, 1])\n",
    "    lab = 'Fold %d PR AUC=%.4f' % (i+1, auc(recall, precision))\n",
    "    pr_auc.append(auc(recall, precision))\n",
    "    print (lab)\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    reversed_recall = np.fliplr([recall])[0]\n",
    "    reversed_precision = np.fliplr([precision])[0]\n",
    "    reversed_mean_precision += interp(mean_recall, reversed_recall, reversed_precision)\n",
    "    reversed_mean_precision[0] = 0.0\n",
    "    tprs[-1][0]=0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    i += 1\n",
    "reversed_mean_precision /= FOLDS\n",
    "reversed_mean_precision[0] = 1\n",
    "mean_tpr_discovery = np.mean(tprs, axis=0)\n",
    "mean_tpr_discovery[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr_discovery)\n",
    "print ('mean sensitivity discovery',np.mean(total_sensitivity))\n",
    "print ('mean specificity discovery',np.mean(total_specificity))\n",
    "print ('mean precision discovery',np.mean(mean_precision))\n",
    "print ('mean PR AUC',np.mean(pr_auc))\n",
    "print ('std dev.',np.std(pr_auc))\n",
    "print ('mean ROC AUC',np.mean(aucs))\n",
    "print ('std_dev ROC AUC',np.std(aucs))\n",
    "mean_AUC_disc=np.mean(pr_auc)\n",
    "ROC_AUC_disc=np.mean(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Random forest 10-fold CV on the validation cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 PR AUC=0.6646\n",
      "Fold 2 PR AUC=0.6953\n",
      "Fold 3 PR AUC=0.5521\n",
      "Fold 4 PR AUC=0.8411\n",
      "Fold 5 PR AUC=0.4499\n",
      "Fold 6 PR AUC=0.8148\n",
      "Fold 7 PR AUC=0.6656\n",
      "Fold 8 PR AUC=0.6835\n",
      "Fold 9 PR AUC=0.5826\n",
      "Fold 10 PR AUC=0.7024\n",
      "Validation mean sensitivity 0.651098901098901\n",
      "Validation mean specificity 0.869329268292683\n",
      "Validation mean precision 0.643225238813474\n",
      "mean PR AUC 0.6651764096452646\n",
      "std_dev PR AUC 0.11041580011801376\n",
      "mean ROC AUC 0.81774457250067\n",
      "std_dev ROC AUC 0.06996473620780753\n"
     ]
    }
   ],
   "source": [
    "# Perform 10-fold CV RF classification on the validation set, extract performance metrics for each out-of-sample set\n",
    "X = classifier_validation.reset_index()\n",
    "X.drop(['public_client_id'],1,inplace=True)\n",
    "X=np.array(X)\n",
    "y=np.array(b)\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "FOLDS=10\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "val_reversed_mean_precision = 0.0\n",
    "val_mean_recall = np.linspace(0, 1, 100)\n",
    "mean_precision=[]\n",
    "pr_auc=[]\n",
    "tprs = []\n",
    "aucs = []\n",
    "total_specificity=[]\n",
    "total_sensitivity=[]\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "i = 0\n",
    "for train, test in cv.split(X, y):\n",
    "    probas_ = shannon_clf.fit(X[train], y[train]).predict_proba(X[test])\n",
    "    preds=shannon_clf.predict(X[test])\n",
    "    tn, fp, fn, tp = confusion_matrix(y[test],preds).ravel()\n",
    "    sensitivity=(tp/(tp+fn))\n",
    "    specificity=(tn/(tn+fp))\n",
    "    mean_precision.append(precision_score(y[test],preds))\n",
    "    total_specificity.append(specificity)\n",
    "    total_sensitivity.append(sensitivity)\n",
    "    precision, recall, thresholds= precision_recall_curve(y[test], probas_[:, 1])\n",
    "    lab = 'Fold %d PR AUC=%.4f' % (i+1, auc(recall, precision))\n",
    "    pr_auc.append(auc(recall, precision))\n",
    "    print (lab)\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    reversed_recall = np.fliplr([recall])[0]\n",
    "    reversed_precision = np.fliplr([precision])[0]\n",
    "    val_reversed_mean_precision += interp(val_mean_recall, reversed_recall, reversed_precision)\n",
    "    val_reversed_mean_precision[0] = 0.0\n",
    "    tprs[-1][0]=0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    i += 1\n",
    "val_reversed_mean_precision /= FOLDS\n",
    "val_reversed_mean_precision[0] = 1\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "std_auc = np.std(aucs)\n",
    "print ('Validation mean sensitivity',np.mean(total_sensitivity))\n",
    "print ('Validation mean specificity',np.mean(total_specificity))\n",
    "print ('Validation mean precision',np.mean(mean_precision))\n",
    "print ('mean PR AUC',np.mean(pr_auc))\n",
    "print ('std_dev PR AUC',np.std(pr_auc))\n",
    "print ('mean ROC AUC',np.mean(aucs))\n",
    "print ('std_dev ROC AUC',np.std(aucs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing Predictive Capacity of Clinical Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 77)\n"
     ]
    }
   ],
   "source": [
    "#Assessing classification capacity of clinical labs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.stats as stats\n",
    "C = chemistries_discovery.loc[:,chemistries_discovery.columns!='shannon']\n",
    "y = chemistries_discovery['shannon']\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "Ccolumns=C.columns\n",
    "C = scaler.fit_transform(C)\n",
    "C=pd.DataFrame(data=C,columns=Ccolumns)\n",
    "print (C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(399, 77)\n"
     ]
    }
   ],
   "source": [
    "#Classifying participants in bottom quartile of shannon using 77 clinical labs\n",
    "classifier_chem=pd.DataFrame(index=discovery_mets.index,data=C.set_index(discovery_mets.index))\n",
    "classifier_chem['shannon_quant']=pd.qcut(chemistries_discovery['shannon'],4,labels=False)\n",
    "c=[]\n",
    "for x in classifier_chem['shannon_quant']:\n",
    "    if x==0:\n",
    "        c.append(1)\n",
    "    else:\n",
    "        c.append(0)\n",
    "classifier_chem['shannon_quant']=c\n",
    "print (classifier_chem['shannon_quant'].sum())\n",
    "classifier_chem.drop(['shannon_quant'],1,inplace=True)\n",
    "print (classifier_chem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shannon_clf = RandomForestClassifier(n_estimators=2000,\n",
    "                                 criterion='entropy',\n",
    "                                 bootstrap=False, oob_score=False,class_weight={0:1,1:3.5},\n",
    "                                 max_features='auto',\n",
    "                                 min_samples_split=2,\n",
    "                                 min_samples_leaf=5,\n",
    "                                 max_depth=5,\n",
    "                                 random_state=1,\n",
    "                                 n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean auc auc clinical labs discovery 0.6675632183908046\n",
      "std deviation auc chemistries discovery 0.05156583181943268\n"
     ]
    }
   ],
   "source": [
    "#using cross_val_Score to get mean ROC_auc, and comparing it to scores extracted independently for each CV\n",
    "chem_score=cross_val_score(shannon_clf,classifier_chem, c,cv=10,scoring='roc_auc')\n",
    "print('mean auc auc clinical labs discovery',np.mean(chem_score))\n",
    "print('std deviation auc chemistries discovery',np.std(chem_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 AUC=0.5674\n",
      "Fold 2 AUC=0.3950\n",
      "Fold 3 AUC=0.3864\n",
      "Fold 4 AUC=0.5904\n",
      "Fold 5 AUC=0.3439\n",
      "Fold 6 AUC=0.6221\n",
      "Fold 7 AUC=0.6207\n",
      "Fold 8 AUC=0.4133\n",
      "Fold 9 AUC=0.2947\n",
      "Fold 10 AUC=0.5367\n",
      "precision 0.4536671661671662\n",
      "specificity 0.7960919540229885\n",
      "sensitivity 0.5\n",
      "pr_AUC 0.4770714585758976\n",
      "pr_AUC std. dev. 0.11670937681743301\n",
      "ROC_AUC 0.6675632183908046\n",
      "ROC_AUC std. dev. 0.05156583181943268\n"
     ]
    }
   ],
   "source": [
    "X = classifier_chem.reset_index()\n",
    "X.drop(['public_client_id'],1,inplace=True)\n",
    "X=np.array(X)\n",
    "y=np.array(c)\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "clinical_reversed_mean_precision = 0.0\n",
    "clinical_mean_recall = np.linspace(0, 1, 100)\n",
    "features=pd.DataFrame(index=C.columns)\n",
    "mean_precision=[]\n",
    "pr_auc_clinical=[]\n",
    "tprs = []\n",
    "aucs = []\n",
    "total_specificity=[]\n",
    "total_sensitivity=[]\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "i = 0\n",
    "for train, test in cv.split(X, y):\n",
    "    probas_ = shannon_clf.fit(X[train], y[train]).predict_proba(X[test])\n",
    "    features[i]=list(shannon_clf.feature_importances_)\n",
    "    preds=shannon_clf.predict(X[test])\n",
    "    tn, fp, fn, tp = confusion_matrix(y[test],preds).ravel()\n",
    "    sensitivity=(tp/(tp+fn))\n",
    "    specificity=(tn/(tn+fp))\n",
    "    mean_precision.append(precision_score(y[test],preds))\n",
    "    total_specificity.append(specificity)\n",
    "    total_sensitivity.append(sensitivity)\n",
    "    precision, recall, thresholds= precision_recall_curve(y[test], probas_[:, 1])\n",
    "    lab = 'Fold %d AUC=%.4f' % (i+1, auc(recall, precision))\n",
    "    pr_auc_clinical.append(auc(recall, precision))\n",
    "    print (lab)\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    reversed_recall = np.fliplr([recall])[0]\n",
    "    reversed_precision = np.fliplr([precision])[0]\n",
    "    clinical_reversed_mean_precision += interp(mean_recall, reversed_recall, reversed_precision)\n",
    "    clinical_reversed_mean_precision[0] = 0.0\n",
    "    tprs[-1][0]=0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    i += 1\n",
    "clinical_reversed_mean_precision/= FOLDS\n",
    "clinical_reversed_mean_precision[0] = 1\n",
    "mean_tpr_chemistries = np.mean(tprs, axis=0)\n",
    "mean_tpr_chemistries[-1] = 1.0\n",
    "print ('precision',np.mean(mean_precision))\n",
    "print ('specificity',np.mean(total_specificity))\n",
    "print ('sensitivity',np.mean(total_sensitivity))\n",
    "print ('pr_AUC',np.mean(pr_auc_clinical))\n",
    "print ('pr_AUC std. dev.',np.std(pr_auc_clinical))\n",
    "print ('ROC_AUC',np.mean(np.mean(aucs)))\n",
    "print ('ROC_AUC std. dev.',np.std(aucs))\n",
    "mean_ROC_clinical=np.mean(aucs)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "arivale-py3 - Python",
   "language": "python",
   "name": "conda-env-arivale-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
